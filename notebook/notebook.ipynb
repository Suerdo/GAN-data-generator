{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook GAN para a Geração de Dados Pessoais Fictícios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker('pt_BR')\n",
    "\n",
    "def gerar_rg():\n",
    "    \"\"\"Função para gerar um número de RG brasileiro simulado\"\"\"\n",
    "    rg_numero = ''.join([str(random.randint(0, 9)) for _ in range(8)])  \n",
    "    digito = random.choice(string.digits + string.ascii_uppercase)  \n",
    "    return rg_numero + digito  \n",
    "\n",
    "def gerar_senha():\n",
    "    \"\"\"Função para gerar uma senha aleatória com letras, números e caracteres especiais\"\"\"\n",
    "    tamanho_senha = random.randint(8, 12)  \n",
    "    caracteres = string.ascii_letters + string.digits + string.punctuation\n",
    "    senha = ''.join(random.choice(caracteres) for _ in range(tamanho_senha))\n",
    "    return senha\n",
    "\n",
    "def gerar_nome_email():\n",
    "    \"\"\"Função para gerar nome e e-mail de forma consistente\"\"\"\n",
    "    nome = fake.name()  \n",
    "    primeiro_nome = nome.split()[0].lower()  # Primeiro nome para o e-mail\n",
    "    email = f\"{primeiro_nome}@{fake.free_email_domain()}\"\n",
    "    return nome, email\n",
    "\n",
    "def gera_dados_ficticios(n):\n",
    "    \"\"\"Função geradora de dados fictícios realistas com base no nome, CPF, RG, CNH e outros dados\"\"\"\n",
    "    data = []  \n",
    "\n",
    "    for _ in range(n):\n",
    "        nome, email = gerar_nome_email()  # Gerar nome e e-mail juntos\n",
    "        \n",
    "        nascimento = fake.date_of_birth(minimum_age=18, maximum_age=80)  \n",
    "        data_nascimento = nascimento.strftime('%d/%m/%Y')  \n",
    "        \n",
    "        ts = random.choice([\"A-\", \"A+\", \"B-\", \"B+\", \"AB-\", \"AB+\", \"O-\", \"O+\"])  \n",
    "        \n",
    "        cpf = fake.cpf().replace(\"-\", \"\").replace(\" \", \"\").replace(\".\", \"\")\n",
    "        cpf = f\"{cpf[:3]}.{cpf[3:6]}.{cpf[6:9]}-{cpf[9:]}\"\n",
    "        \n",
    "        cnh = ''.join([str(random.randint(0, 9)) for _ in range(11)])  \n",
    "        \n",
    "        telefone = f\"({random.randint(10, 99)}) {random.randint(90000, 99999)}-{random.randint(1000, 9999)}\"  \n",
    "        \n",
    "        endereco = fake.address().replace(\"\\n\", \", \")  \n",
    "        \n",
    "        rg = gerar_rg()\n",
    "\n",
    "        login = nome.split()[0].lower() + str(random.randint(100, 999))\n",
    "        \n",
    "        senha = gerar_senha()\n",
    "        \n",
    "        data.append([nome, data_nascimento, email, ts, cpf, rg, cnh, telefone, endereco, login, senha])\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"Nome\", \"Data de Nascimento\", \"Email\", \"Tipo Sanguíneo\", \"CPF\", \"RG\", \"CNH\", \"Telefone\", \"Endereço\", \"Login\", \"Senha\"])\n",
    "\n",
    "# Função para gerar dados fictícios com o GAN (mas agora sem os campos de nome, email e CPF)\n",
    "def build_generator(latent_dim):\n",
    "    \"\"\"Função para construir o gerador do modelo GAN\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu', input_dim=latent_dim))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dense(9, activation='sigmoid'))  \n",
    "    return model\n",
    "\n",
    "# Discriminador\n",
    "def build_discriminator():\n",
    "    \"\"\"Função para construir o discriminador do modelo GAN\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(512, activation='relu', input_dim=9))  \n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  \n",
    "    return model\n",
    "\n",
    "# Modelo GAN\n",
    "def build_gan(generator, discriminator):\n",
    "    \"\"\"Função para construir o modelo GAN combinando gerador e discriminador\"\"\"\n",
    "    discriminator.trainable = False  \n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "latent_dim = 100\n",
    "\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator()\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n",
    "# Função para treinar o modelo GAN\n",
    "def train_gan(epochs, batch_size, latent_dim, data):\n",
    "    \"\"\"Função para treinar o modelo GAN\"\"\"\n",
    "    batch_count = data.shape[0] // batch_size\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(batch_count):\n",
    "            # 1. Treinar o discriminador com dados reais e gerados\n",
    "            real_data = data.sample(batch_size).values\n",
    "            fake_data = gera_dados_ficticios(batch_size).values  # Gerando dados falsos com o gerador\n",
    "            \n",
    "            # Etiquetas para dados reais e gerados\n",
    "            real_labels = np.ones((batch_size, 1))\n",
    "            fake_labels = np.zeros((batch_size, 1))\n",
    "            \n",
    "            # Treinando o discriminador\n",
    "            discriminator_loss_real = discriminator.train_on_batch(real_data, real_labels)\n",
    "            discriminator_loss_fake = discriminator.train_on_batch(fake_data, fake_labels)\n",
    "            \n",
    "            # 2. Treinar o gerador\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            gan_labels = np.ones((batch_size, 1))  # O gerador quer enganar o discriminador\n",
    "            \n",
    "            generator_loss = gan.train_on_batch(noise, gan_labels)\n",
    "        \n",
    "        print(f\"{epoch+1}/{epochs} | D Loss Real: {discriminator_loss_real[0]} | D Loss Fake: {discriminator_loss_fake[0]} | G Loss: {generator_loss[0]}\")\n",
    "\n",
    "# Gerar dados reais para treinamento\n",
    "dados_ficticios = gera_dados_ficticios(1000)\n",
    "\n",
    "# Gerar 100 novos registros com o gerador treinado (os campos de nome, email e CPF são fixos)\n",
    "new_data = gera_dados_ficticios(100)\n",
    "\n",
    "# Exportando para Excel\n",
    "new_data.to_excel('dados_pessoais_ficticios_gerados3.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
